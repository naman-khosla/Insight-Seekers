{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>global_num</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22/01/2020</td>\n",
       "      <td>Gyeonggi-do_Gimpo-si</td>\n",
       "      <td>37.615246</td>\n",
       "      <td>126.715632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24/01/2020</td>\n",
       "      <td>Seoul_Jung-gu</td>\n",
       "      <td>37.567241</td>\n",
       "      <td>127.005659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26/01/2020</td>\n",
       "      <td>Seoul_Seongdong-gu</td>\n",
       "      <td>37.563992</td>\n",
       "      <td>127.029534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27/01/2020</td>\n",
       "      <td>Seoul_Dongdaemun-gu</td>\n",
       "      <td>37.566262</td>\n",
       "      <td>127.065815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28/01/2020</td>\n",
       "      <td>Seoul_Gangnam-gu</td>\n",
       "      <td>37.523674</td>\n",
       "      <td>127.046543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>6100000083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/03/2020</td>\n",
       "      <td>Daegu_Buk-gu</td>\n",
       "      <td>35.891794</td>\n",
       "      <td>128.588890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>6100000085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/03/2020</td>\n",
       "      <td>Gyeongsangnam-do_Changwon-si</td>\n",
       "      <td>35.227956</td>\n",
       "      <td>128.685595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>6100000086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2020</td>\n",
       "      <td>Daegu_Dalseong-gun</td>\n",
       "      <td>35.857185</td>\n",
       "      <td>128.466686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>6100000090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>Incheon_Jung-gu</td>\n",
       "      <td>37.460191</td>\n",
       "      <td>126.440696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>6100000090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>Busan_Gangseo-gu</td>\n",
       "      <td>35.173220</td>\n",
       "      <td>128.946459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1509 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  global_num        date                      location  \\\n",
       "0     1000000001         2.0  22/01/2020          Gyeonggi-do_Gimpo-si   \n",
       "1     1000000001         2.0  24/01/2020                 Seoul_Jung-gu   \n",
       "2     1000000002         5.0  26/01/2020            Seoul_Seongdong-gu   \n",
       "3     1000000002         5.0  27/01/2020           Seoul_Dongdaemun-gu   \n",
       "4     1000000002         5.0  28/01/2020              Seoul_Gangnam-gu   \n",
       "...          ...         ...         ...                           ...   \n",
       "1504  6100000083         NaN   6/03/2020                  Daegu_Buk-gu   \n",
       "1505  6100000085         NaN  16/03/2020  Gyeongsangnam-do_Changwon-si   \n",
       "1506  6100000086         NaN  14/03/2020            Daegu_Dalseong-gun   \n",
       "1507  6100000090         NaN  24/03/2020               Incheon_Jung-gu   \n",
       "1508  6100000090         NaN  24/03/2020              Busan_Gangseo-gu   \n",
       "\n",
       "       latitude   longitude  \n",
       "0     37.615246  126.715632  \n",
       "1     37.567241  127.005659  \n",
       "2     37.563992  127.029534  \n",
       "3     37.566262  127.065815  \n",
       "4     37.523674  127.046543  \n",
       "...         ...         ...  \n",
       "1504  35.891794  128.588890  \n",
       "1505  35.227956  128.685595  \n",
       "1506  35.857185  128.466686  \n",
       "1507  37.460191  126.440696  \n",
       "1508  35.173220  128.946459  \n",
       "\n",
       "[1509 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the bank transaction dataset\n",
    "df = pd.read_csv('D1.csv')\n",
    "# info and the first 10 transactions\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Task 1\n",
    "# 1. What pre-processing was required on the dataset before building the association mining \n",
    "model? What variables did you include in the analysis? Justify your choice.\n",
    "- convert date to correct format (todatetime)\n",
    "- fill the missing values in \"global_num\"\n",
    "- sort data by date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date from OBJECT to DATETIME\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'],infer_datetime_format=True)\n",
    "\n",
    "#Replace null values with mode of blood_type\n",
    "\n",
    "global_mode = df['global_num'].mode()[0]\n",
    "df['global_num'].fillna(global_mode, inplace = True)\n",
    "\n",
    "#sort data by date column\n",
    "df= df.sort_values(by='date', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1509 entries, 0 to 748\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   patient_id  1509 non-null   int64         \n",
      " 1   global_num  1509 non-null   float64       \n",
      " 2   date        1509 non-null   datetime64[ns]\n",
      " 3   location    1509 non-null   object        \n",
      " 4   latitude    1509 non-null   float64       \n",
      " 5   longitude   1509 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(1)\n",
      "memory usage: 82.5+ KB\n",
      "None\n",
      "      patient_id  global_num       date                 location   latitude  \\\n",
      "0     1000000001         2.0 2020-01-22     Gyeonggi-do_Gimpo-si  37.615246   \n",
      "1095  2000000001         3.0 2020-01-24    Gyeonggi-do_Goyang-si  37.677860   \n",
      "1098  2000000006        17.0 2020-01-24       Incheon_Namdong-gu  37.456256   \n",
      "1     1000000001         2.0 2020-01-24            Seoul_Jung-gu  37.567241   \n",
      "958   1300000001        16.0 2020-01-25           Gwangju_Nam-gu  35.082297   \n",
      "1099  2000000006        17.0 2020-01-25         Daegu_Suseong-gu  35.854077   \n",
      "1100  2000000006        17.0 2020-01-25         Seoul_Gangnam-gu  37.487468   \n",
      "1101  2000000006        17.0 2020-01-25        Seoul_Gwangjin-gu  37.545475   \n",
      "1237  5000000001         8.0 2020-01-25          Seoul_Seocho-gu  37.491098   \n",
      "959   1300000001        16.0 2020-01-25     Jeollanam-do_Naju-si  35.016060   \n",
      "1096  2000000002         4.0 2020-01-26  Gyeonggi-do_Seongnam-si  37.352067   \n",
      "21    1000000017        83.0 2020-01-26          Seoul_Jongno-gu  37.586288   \n",
      "2     1000000002         5.0 2020-01-26       Seoul_Seongdong-gu  37.563992   \n",
      "960   1300000002        18.0 2020-01-27      Gwangju_Gwangsan-gu  35.175904   \n",
      "3     1000000002         5.0 2020-01-27      Seoul_Dongdaemun-gu  37.566262   \n",
      "4     1000000002         5.0 2020-01-28         Seoul_Gangnam-gu  37.523674   \n",
      "1238  5000000001         8.0 2020-01-30    Jeollabuk-do_Iksan-si  35.964332   \n",
      "5     1000000004         7.0 2020-01-30        Seoul_Jungnang-gu  37.612772   \n",
      "7     1000000006        10.0 2020-01-30    Gyeonggi-do_Goyang-si  37.641141   \n",
      "8     1000000007        11.0 2020-01-30    Gyeonggi-do_Goyang-si  37.641141   \n",
      "\n",
      "       longitude  \n",
      "0     126.715632  \n",
      "1095  126.812175  \n",
      "1098  126.705206  \n",
      "1     127.005659  \n",
      "958   126.830196  \n",
      "1099  128.615277  \n",
      "1100  127.101325  \n",
      "1101  127.103235  \n",
      "1237  127.011853  \n",
      "959   126.710757  \n",
      "1096  127.123177  \n",
      "21    126.999716  \n",
      "2     127.029534  \n",
      "960   126.818064  \n",
      "3     127.065815  \n",
      "4     127.046543  \n",
      "1238  126.959654  \n",
      "5     127.098167  \n",
      "7     126.791968  \n",
      "8     126.791968  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id\n",
      "1000000001                [Gyeonggi-do_Gimpo-si, Seoul_Jung-gu]\n",
      "1000000002    [Seoul_Seongdong-gu, Seoul_Dongdaemun-gu, Seou...\n",
      "1000000004                                  [Seoul_Jungnang-gu]\n",
      "1000000005                                  [Seoul_Jungnang-gu]\n",
      "1000000006                              [Gyeonggi-do_Goyang-si]\n",
      "Name: location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# group by account, then list all services\n",
    "transactions = df.groupby(['patient_id'])['location'].apply(list)\n",
    "print(transactions.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apyori in /Users/naman/opt/anaconda3/lib/python3.9/site-packages (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelationRecord(items=frozenset({'Busan_Yeonje-gu'}), support=0.05723905723905724, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Busan_Yeonje-gu'}), confidence=0.05723905723905724, lift=1.0)]), RelationRecord(items=frozenset({'Daegu_Jung-gu'}), support=0.05499438832772166, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Daegu_Jung-gu'}), confidence=0.05499438832772166, lift=1.0)]), RelationRecord(items=frozenset({'Incheon_Jung-gu'}), support=0.14927048260381592, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Incheon_Jung-gu'}), confidence=0.14927048260381592, lift=1.0)]), RelationRecord(items=frozenset({'Seoul_Dongjak-gu'}), support=0.08866442199775533, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Seoul_Dongjak-gu'}), confidence=0.08866442199775533, lift=1.0)]), RelationRecord(items=frozenset({'Seoul_Gangnam-gu'}), support=0.05611672278338945, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Seoul_Gangnam-gu'}), confidence=0.05611672278338945, lift=1.0)])]\n"
     ]
    }
   ],
   "source": [
    "from apyori import apriori\n",
    "# type cast the transactions from pandas into normal list format and run apriori\n",
    "transaction_list = list(transactions)\n",
    "results = list(apriori(transaction_list, min_support=0.002, min_confidence=0.05))\n",
    "# print first 5 rules\n",
    "print(results[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Left_side          Right_side   Support  Confidence        Lift\n",
      "0                         Busan_Yeonje-gu  0.057239    0.057239    1.000000\n",
      "1                           Daegu_Jung-gu  0.054994    0.054994    1.000000\n",
      "2                         Incheon_Jung-gu  0.149270    0.149270    1.000000\n",
      "3                        Seoul_Dongjak-gu  0.088664    0.088664    1.000000\n",
      "4                        Seoul_Gangnam-gu  0.056117    0.056117    1.000000\n",
      "5                           Seoul_Jung-gu  0.063973    0.063973    1.000000\n",
      "6                       Seoul_Jungnang-gu  0.088664    0.088664    1.000000\n",
      "7                      Seoul_Yangcheon-gu  0.060606    0.060606    1.000000\n",
      "8        Busan_Buk-gu    Busan_Gangseo-gu  0.003367    0.600000   76.371429\n",
      "9    Busan_Gangseo-gu        Busan_Buk-gu  0.003367    0.428571   76.371429\n",
      "10       Busan_Buk-gu     Busan_Yeonje-gu  0.003367    0.600000   10.482353\n",
      "11    Busan_Yeonje-gu        Busan_Buk-gu  0.003367    0.058824   10.482353\n",
      "12       Busan_Buk-gu      Gwangju_Buk-gu  0.002245    0.400000  118.800000\n",
      "13     Gwangju_Buk-gu        Busan_Buk-gu  0.002245    0.666667  118.800000\n",
      "14  Busan_Busanjin-gu        Busan_Seo-gu  0.002245    0.181818   10.800000\n",
      "15       Busan_Seo-gu   Busan_Busanjin-gu  0.002245    0.133333   10.800000\n",
      "16  Busan_Busanjin-gu     Busan_Yeonje-gu  0.006734    0.545455    9.529412\n",
      "17    Busan_Yeonje-gu   Busan_Busanjin-gu  0.006734    0.117647    9.529412\n",
      "18      Busan_Dong-gu     Busan_Yeonje-gu  0.007856    0.700000   12.229412\n",
      "19    Busan_Yeonje-gu       Busan_Dong-gu  0.007856    0.137255   12.229412\n"
     ]
    }
   ],
   "source": [
    "def convert_apriori_results_to_pandas_df(results):\n",
    "    rules = []\n",
    "    for rule_set in results:\n",
    "         for rule in rule_set.ordered_statistics:\n",
    "     # items_base = left side of rules, items_add = right side\n",
    "     # support, confidence and lift for respective rules\n",
    "             rules.append([','.join(rule.items_base), ','.join(rule.items_add),\n",
    "                 rule_set.support, rule.confidence, rule.lift])\n",
    " \n",
    "     # typecast it to pandas df\n",
    "    return pd.DataFrame(rules, columns=['Left_side', 'Right_side', 'Support', 'Confidence', 'Lift'])\n",
    "result_df = convert_apriori_results_to_pandas_df(results)\n",
    "print(result_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Left_side  \\\n",
      "368             Seoul_Jung-gu,Daegu_Buk-gu   \n",
      "288         Chungcheongbuk-do_Jincheon-gun   \n",
      "369          Seoul_Dongjak-gu,Daegu_Seo-gu   \n",
      "293  Daegu_Suseong-gu,Gyeonggi-do_Suwon-si   \n",
      "370             Seoul_Jung-gu,Daegu_Seo-gu   \n",
      "\n",
      "                                Right_side   Support  Confidence   Lift  \n",
      "368          Seoul_Dongjak-gu,Daegu_Seo-gu  0.002245    1.000000  445.5  \n",
      "288  Daegu_Suseong-gu,Gyeonggi-do_Suwon-si  0.002245    1.000000  445.5  \n",
      "369             Seoul_Jung-gu,Daegu_Buk-gu  0.002245    1.000000  445.5  \n",
      "293         Chungcheongbuk-do_Jincheon-gun  0.002245    1.000000  445.5  \n",
      "370          Daegu_Buk-gu,Seoul_Dongjak-gu  0.002245    0.666667  297.0  \n"
     ]
    }
   ],
   "source": [
    "# sort all acquired rules descending by lift\n",
    "result_df = result_df.sort_values(by='Lift', ascending=False)\n",
    "print(result_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. List four most interesting routes taken by individuals who have tested positive for \n",
    "COVID19 and have travelled from Buk-gu City in Busan Province. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left_side</th>\n",
       "      <th>Right_side</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Busan_Buk-gu</td>\n",
       "      <td>Busan_Yeonje-gu,Gwangju_Buk-gu</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.4</td>\n",
       "      <td>118.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Busan_Buk-gu</td>\n",
       "      <td>Gwangju_Buk-gu</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.4</td>\n",
       "      <td>118.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Busan_Buk-gu</td>\n",
       "      <td>Busan_Gangseo-gu,Busan_Yeonje-gu</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.4</td>\n",
       "      <td>118.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Busan_Buk-gu</td>\n",
       "      <td>Busan_Gangseo-gu</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.6</td>\n",
       "      <td>76.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Busan_Buk-gu</td>\n",
       "      <td>Busan_Yeonje-gu</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.482353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Left_side                        Right_side   Support  Confidence  \\\n",
       "260  Busan_Buk-gu    Busan_Yeonje-gu,Gwangju_Buk-gu  0.002245         0.4   \n",
       "12   Busan_Buk-gu                    Gwangju_Buk-gu  0.002245         0.4   \n",
       "255  Busan_Buk-gu  Busan_Gangseo-gu,Busan_Yeonje-gu  0.002245         0.4   \n",
       "8    Busan_Buk-gu                  Busan_Gangseo-gu  0.003367         0.6   \n",
       "10   Busan_Buk-gu                   Busan_Yeonje-gu  0.003367         0.6   \n",
       "\n",
       "           Lift  \n",
       "260  118.800000  \n",
       "12   118.800000  \n",
       "255  118.800000  \n",
       "8     76.371429  \n",
       "10    10.482353  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[(result_df['Left_side'] == 'Busan_Buk-gu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequantial  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gyeonggi-do_Gimpo-si', 'Seoul_Jung-gu'], ['Seoul_Seongdong-gu', 'Seoul_Dongdaemun-gu', 'Seoul_Gangnam-gu'], ['Seoul_Jungnang-gu'], ['Seoul_Jungnang-gu'], ['Gyeonggi-do_Goyang-si']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transactions = df.groupby(['patient_id'])['location'].apply(list)\n",
    "sequences = transactions.values.tolist()\n",
    "# show the first 5 sequences\n",
    "print(sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "''' Uses SPMF to find association rules in supplied transactions '''\n",
    "def get_association_rules(sequences, min_sup, min_conf):\n",
    "    # step 1: create required input for SPMF\n",
    "    \n",
    "    # prepare a dict to uniquely assign each item in the transactions to an int ID\n",
    "    item_dict = defaultdict(int)\n",
    "    output_dict = defaultdict(str)\n",
    "    item_id = 1\n",
    "    \n",
    "    # write your sequences in SPMF format\n",
    "    with open('seq_rule_input.txt', 'w+') as f:\n",
    "        for sequence in sequences:\n",
    "            z = []\n",
    "            for itemset in sequence:\n",
    "                # if there are multiple items in one itemset\n",
    "                if isinstance(itemset, list):\n",
    "                    for item in itemset:\n",
    "                        if item not in item_dict:\n",
    "                            item_dict[item] = item_id\n",
    "                            item_id += 1\n",
    "\n",
    "                        z.append(item_dict[item])\n",
    "                else:\n",
    "                    if itemset not in item_dict:\n",
    "                        item_dict[itemset] = item_id\n",
    "                        output_dict[str(item_id)] = itemset\n",
    "                        item_id += 1\n",
    "                    z.append(item_dict[itemset])\n",
    "                    \n",
    "                # end of itemset\n",
    "                z.append(-1)\n",
    "            \n",
    "            # end of a sequence\n",
    "            z.append(-2)\n",
    "            f.write(' '.join([str(x) for x in z]))\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # run SPMF with supplied parameters\n",
    "    supp_param = '{}%'.format(int(min_sup * 100))\n",
    "    conf_param = '{}%'.format(int(min_conf * 100))\n",
    "    subprocess.call(['java', '-jar', 'spmf.jar', 'run', 'RuleGrowth', \n",
    "                     'seq_rule_input.txt', 'seq_rule_output.txt', \n",
    "                     supp_param, conf_param], shell=True)\n",
    "    \n",
    "    # read back the output rules\n",
    "    outputs = open('seq_rule_output.txt', 'r').read().strip().split('\\n')\n",
    "    output_rules = []\n",
    "    for rule in outputs:\n",
    "        left, right, sup, conf = re.search(pattern=r'([0-9\\,]+) ==> ([0-9\\,]+) #SUP: ([0-9]+) #CONF: ([0-9\\.]+)', string=rule).groups()\n",
    "        sup = int(sup) / len(sequences)\n",
    "        conf = float(conf)\n",
    "        output_rules.append([[output_dict[x] for x in left.split(',')], [output_dict[x] for x in right.split(',')], sup, conf])\n",
    "    \n",
    "    print(outputs)\n",
    "    return pd.DataFrame(output_rules, columns=['Left_rule', 'Right_rule', 'Support', 'Confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "\n",
    "def get_association_rules(sequences, min_sup, min_conf):\n",
    "    # ...\n",
    "\n",
    "    # Update the file path to the absolute file path of seq_rule_output.txt\n",
    "    output_file_path = \"Documents/Documents - Naman’s MacBook Pro/Sem 1 Courses/IFN509 Data Exploration & Mining/Assessment/Assessment 2/Project datasets/seq_rule_input.txt\"\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # run SPMF with supplied parameters\n",
    "    supp_param = '{}%'.format(int(min_sup * 100))\n",
    "    conf_param = '{}%'.format(int(min_conf * 100))\n",
    "    subprocess.call(['java', '-jar', 'spmf.jar', 'run', 'RuleGrowth', \n",
    "                     'seq_rule_input.txt', output_file_path, \n",
    "                     supp_param, conf_param], shell=True)\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # read back the output rules\n",
    "    outputs = open(output_file_path, 'r').read().strip().split('\\n')\n",
    "    \n",
    "    # ...\n",
    "\n",
    "    return pd.DataFrame(output_rules, columns=['Left_rule', 'Right_rule', 'Support', 'Confidence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three sequences 12 ==>5, 12==>6, 17==>45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: java [-options] class [args...]\n",
      "           (to execute a class)\n",
      "   or  java [-options] -jar jarfile [args...]\n",
      "           (to execute a jar file)\n",
      "where options include:\n",
      "    -d32\t  use a 32-bit data model if available\n",
      "    -d64\t  use a 64-bit data model if available\n",
      "    -server\t  to select the \"server\" VM\n",
      "                  The default VM is server,\n",
      "                  because you are running on a server-class machine.\n",
      "\n",
      "\n",
      "    -cp <class search path of directories and zip/jar files>\n",
      "    -classpath <class search path of directories and zip/jar files>\n",
      "                  A : separated list of directories, JAR archives,\n",
      "                  and ZIP archives to search for class files.\n",
      "    -D<name>=<value>\n",
      "                  set a system property\n",
      "    -verbose:[class|gc|jni]\n",
      "                  enable verbose output\n",
      "    -version      print product version and exit\n",
      "    -version:<value>\n",
      "                  Warning: this feature is deprecated and will be removed\n",
      "                  in a future release.\n",
      "                  require the specified version to run\n",
      "    -showversion  print product version and continue\n",
      "    -jre-restrict-search | -no-jre-restrict-search\n",
      "                  Warning: this feature is deprecated and will be removed\n",
      "                  in a future release.\n",
      "                  include/exclude user private JREs in the version search\n",
      "    -? -help      print this help message\n",
      "    -X            print help on non-standard options\n",
      "    -ea[:<packagename>...|:<classname>]\n",
      "    -enableassertions[:<packagename>...|:<classname>]\n",
      "                  enable assertions with specified granularity\n",
      "    -da[:<packagename>...|:<classname>]\n",
      "    -disableassertions[:<packagename>...|:<classname>]\n",
      "                  disable assertions with specified granularity\n",
      "    -esa | -enablesystemassertions\n",
      "                  enable system assertions\n",
      "    -dsa | -disablesystemassertions\n",
      "                  disable system assertions\n",
      "    -agentlib:<libname>[=<options>]\n",
      "                  load native agent library <libname>, e.g. -agentlib:hprof\n",
      "                  see also, -agentlib:jdwp=help and -agentlib:hprof=help\n",
      "    -agentpath:<pathname>[=<options>]\n",
      "                  load native agent library by full pathname\n",
      "    -javaagent:<jarpath>[=<options>]\n",
      "                  load Java programming language agent, see java.lang.instrument\n",
      "    -splash:<imagepath>\n",
      "                  show splash screen with specified image\n",
      "See http://www.oracle.com/technetwork/java/javase/documentation/index.html for more details.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/Documents - Naman’s MacBook Pro/Sem 1 Courses/IFN509 Data Exploration & Mining/Assessment/Assessment 2/Project datasets/seq_rule_input.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b5/sp6hfws91yl00720lq7qy0c80000gn/T/ipykernel_8795/2015819441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_association_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/b5/sp6hfws91yl00720lq7qy0c80000gn/T/ipykernel_8795/2395008029.py\u001b[0m in \u001b[0;36mget_association_rules\u001b[0;34m(sequences, min_sup, min_conf)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# read back the output rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/Documents - Naman’s MacBook Pro/Sem 1 Courses/IFN509 Data Exploration & Mining/Assessment/Assessment 2/Project datasets/seq_rule_input.txt'"
     ]
    }
   ],
   "source": [
    "get_association_rules(sequences, 0.01, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
